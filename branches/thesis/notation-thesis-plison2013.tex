
\chapter*{Mathematical notations}
\thispagestyle{empty}

\note{Need to work on this}

\begin{tabular}{lp{5mm}p{11cm}}
\multicolumn{3}{l}{\textbf{Probabilistic models:}} \\
$P(x)$ && Probability distribution for the random variable $x$ \\
$P(x_1, ...x_n)$ && Joint probability distribution for $x_1$, ... $x_n$ \\
$P(x_1,...x_n | y_1, ... y_n)$ && Conditional probability distribution for $x_1$, ... $x_n$ given $y_1$, ... $y_n$  \\ 
$E(x)$ && Expectation of the variable $x$ \vspace{4mm} \\
\multicolumn{3}{l}{\textbf{(Partially observable) Markov Decision Processes:}} \\
$s$ && Current state \\
$\mathcal{S}$ && Set of possible states \\
$s_t$ && State at time $t$ \\
$a$ && System action \\ 
$\mathcal{A}$ && Set of possible actions \\
$o$ && Observation \\
$\mathcal{O}$ && Set of possible observations \\
$R(s,a)$ && Immediate reward of action $a$ in state $s$ \\
$\gamma$ && Discount factor \\
$h$ && Planning horizon \\
$Q(s,a)$ && Utility  of action $a$ in state $s$ (=expected cumulative reward) \\
$b$ && Belief state $b(s) = P(s)$ \\
$Q(b,a)$ && Utility  of action $a$ in belief state $b$ \\
$\pi(b)$ && Dialogue policy, defined as a function $\pi: b \rightarrow a$ \\

&&  \vspace{4mm} \\
\multicolumn{3}{l}{\textbf{Dialogue management:}} \\

$u_u$ && User utterance \\
$\tilde{u}_u$ && Actual recognition hypotheses $\langle (u_u^1, p^1), ... (u_u^n, p^n)\rangle$ for user utterance, where $u_u^i$ is an hypothesis with probability $p^i$ \\
$a_u$ && User dialogue act \\
$\tilde{a}_u$ && Actual interpretation hypotheses $\langle (a_u^1, p^1), ... (a_u^n, p^n)\rangle$ for the user dialogue act \\
$i_u$ && User intention \\
$c$ && External context \\
$a_m$ && System dialogue act \\
$u_m$ && System utterance \\

\end{tabular}
